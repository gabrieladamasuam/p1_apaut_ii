{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 1: KNN y selección de atributos**\n",
    "\n",
    "**Eva Blazquez y Gabriela Damas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Implementación y uso de KNN**\n",
    "\n",
    "**a) Descargue los datos del siguiente problema relacionado con el cáncer de mama:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Preprocese el dataset siguiendo estos pasos: (1) separe los atributos de la etiquetas; (2) divida los datos en una partición con el 70 % de los puntos para training y el 30 % de los puntos para test; (3) normalice los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# (1) Separar atributos de las etiquetas\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# (2) Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# (3) Escalar y normalizar los datos\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Si hubiera datos ausentes (missing values) y estos se completaran, ¿cómo cree que influiría el orden en el que se realizan las operaciones de normalizar y completar? ¿Qué pasaría si primero se completan los datos ausentes y luego se normaliza? ¿Y si primero se normaliza y luego se realiza la partición training-test?**\n",
    "\n",
    "**Respuesta:**  \n",
    "- Si primero completamos los missing values y luego normalizamos, la normalización se hace sobre datos completos, lo cual es correcto.\n",
    "- Si primero normalizamos y luego completamos, los valores imputados no estarán correctamente escalados respecto al resto.\n",
    "- Si primero normalizamos y luego partimos en train/test, puedes tener \"fugas de información\" porque la media y desviación estándar se calculan usando datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) A continuación, complete la clase KNNClassifier, cuyos atributos son el número de vecinos y una función distancia (una función cuyas entradas son dos vectores de la misma dimensión, y cuya salida es un número real positivo). Complete el constructor y los métodos fit y predict.**\n",
    "\n",
    "[Ver KNNClassifier.py](./KNNClassifier.py)\n",
    "\n",
    "**e) Utilice la clase anterior para predecir las etiquetas de los datos de test, con un número de vecinos $k$, fijo pero arbitrario.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNNClassifier import KNNClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNNClassifier(k=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_predcustom = knn.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predcustom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Responda a la siguiente pregunta: ¿Qué ocurriría si hubiera un desbalanceo de clases en el conjunto de entrenamiento? Si esto supone un problema, ¿podría proporcionar una solución?**\n",
    "\n",
    "**Respuesta:** Si hay desbalanceo de clases, KNN puede estar sesgado hacia la clase mayoritaria. Una solución es ponderar el voto de los vecinos por la inversa de la distancia o usar técnicas de sobremuestreo/submuestreo, o ajustar el umbral de decisión.\n",
    "\n",
    "**g) Responda a la siguiente pregunta: ¿Cuál es el coste en memoria del algoritmo KNN? ¿Se le ocurre alguna forma de reducirlo?**\n",
    "\n",
    "**Respuesta:** KNN almacena todo el conjunto de entrenamiento, por lo que el coste en memoria es $O(n \\cdot d)$, siendo $n$ el número de muestras y $d$ el número de atributos. Para reducirlo se pueden usar prototipos (condensed KNN), clustering, o reducción de dimensionalidad.\n",
    "\n",
    "**h) Utilice la función KNeighborsClassifier de la biblioteca de sklearn y, para el mismo número de vecinos $k$ prediga las etiquetas del conjunto de test $y_{\\text{predsk}}$. Si $y_{\\text{predsk}}$ son las prediciones de su modelo, ¿cuál es el error medio entre las predicciones $y_{\\text{predsk}}$ e $y_{\\text{predcustom}}$? ¿Por qué?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "knn_sk = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_sk.fit(X_train_scaled, y_train)\n",
    "y_predsk = knn_sk.predict(X_test_scaled)\n",
    "print(\"Error medio entre predicciones:\", mean_squared_error(y_predcustom, y_predsk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) Se encuentra usted a un individuo que afirma que, en vez de utilizar KNN, el prefiere usar la siguiente alternativa. Para predecir la etiqueta del punto $x$, toma los tres puntos más cercanos a $x$ en el conjunto de training. Si las distancias de estos tres puntos al punto $x$ son $d_1$, $d_2$ e $d_3$, y sus respectivas etiquetas son $y_1$, $y_2$ e $y_3$, la predicción vendrá dada por**\n",
    "\n",
    "$$\n",
    "f(x) = \\operatorname{sign} \\left( \\sum_{i=1}^{3} \\frac{y_i}{d_i} \\right).\n",
    "$$\n",
    "\n",
    "**¿Considera que este método es mejor que KNN con $k = 3$? ¿Por qué?**\n",
    "\n",
    "_Inciso:_ En KNN “clásico”, cada uno de los $k=3$ vecinos cercanos votaría con el mismo peso y se elegiría la clase mayoritaria. La idea propuesta es una variante de KNN donde cada vecino contribuye con un peso inverso a su distancia $(\\frac{1}{d})$.\n",
    "\n",
    "Si el punto a clasificar es muy próximo a un ejemplo de una clase y lejano a ejemplos de la otra, tiene sentido darle más importancia al cercano. Esto ayuda cuando hay mezcla de clases alrededor del punto y cuando la cercanía es un indicador fuerte de pertenencia a la clase correcta. Sin embargo, si alguna distancia es muy pequeña (casi 0), $\\frac{1}{d}$ se dispara y la predicción queda dominada por ese único vecino, comportándose casi como $k=1$.\n",
    "\n",
    "**Respuesta:** Depende. En muchos problemas puede igualar o mejorar ligeramente, pero también puede volverse más sensible a outliers y a mediciones de distancia ruidosas. La recomendación práctica es validarlo con validación cruzada en los datos concretos y escoger la variante que mejor funcione en promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Optimización de KNN**\n",
    "\n",
    "**a) Encuentre, utilizando validación cruzada, el número de vecinos óptimos, $k_{\\text{opt}}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # Evitar warnings de sklearn\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNNClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {'knn__k': list(range(1, 31))}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "k_opt = grid.best_params_['knn__k']\n",
    "print(f\"k óptimo: {k_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) De la métrica de accuracy sobre el conjunto de test del clasificador KNN usando el valor $k_{\\text{opt}}$ obtenido.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos directamente el mejor estimador ya reentrenado en todo X_train (refit=True por defecto)\n",
    "best_estimator = grid.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "print(\"Accuracy sobre el conjunto de test:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) ¿Cree que el valor $k_{\\text{opt}}$ encontrado es el que proporciona mejor accuracy en el conjunto de test?**\n",
    "\n",
    "**Respuesta:** No necesariamente. $k_{\\text{opt}}$ es el valor que mejor funcionó en validación cruzada dentro del conjunto de entrenamiento, por lo que es el que se espera que generalice mejor “en promedio”. Sin embargo, el conjunto de test es una única muestra aleatoria: por variabilidad, puede ocurrir que otro $k$ dé una accuracy ligeramente mayor en ese test concreto.\n",
    "\n",
    "La buena práctica es: elegir $k_{\\text{opt}}$ solo con validación cruzada en train (dentro de un Pipeline para evitar fugas), reentrenar con todo el train usando $k_{\\text{opt}}$ y evaluar una única vez en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Muestre en una gráfica el accuracy frente al número de vecinos, tanto para el conjunto de training como para el de test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_values = list(range(1, 31))\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for k in k_values:\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('knn', KNNClassifier(k=k))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    train_acc.append(accuracy_score(y_train, pipe.predict(X_train)))\n",
    "    test_acc.append(accuracy_score(y_test, pipe.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_values, train_acc, label='Train')\n",
    "plt.plot(k_values, test_acc, label='Test')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy/k en Train y Test')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta curva es la esperada en KNN: el accuracy en train suele ser máximo en $k=1$ y disminuye suavemente al aumentar $k$; en test aparece un pico para $k$ pequeño/medio y luego se estabiliza con ligeras oscilaciones (posibles empates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Repita los experimentos anteriores utilizando la distancia de Minkowski para $p ∈ {1, 2, 10}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [1, 2, 10]\n",
    "k_values = list(range(1, 31))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "k_opt_dict = {}\n",
    "best_by_p = {}\n",
    "\n",
    "for p in p_values:\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('knn', KNNClassifier(p=p))\n",
    "    ])\n",
    "    grid = GridSearchCV(pipe, {'knn__k': k_values}, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    k_opt = grid.best_params_['knn__k']\n",
    "    k_opt_dict[p] = k_opt\n",
    "    best_by_p[p] = grid.best_estimator_\n",
    "    print(f\"Para p={p}, el k óptimo = {k_opt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación en test usando el MISMO preprocesado (Pipeline)\n",
    "for p in p_values:\n",
    "    y_test_pred = best_by_p[p].predict(X_test)\n",
    "    print(f\"Para p={p}, el test accuracy = {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for p in p_values:\n",
    "    train_acc, test_acc = [], []\n",
    "    for k in k_values:\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('knn', KNNClassifier(k=k, p=p))\n",
    "        ])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        train_acc.append(accuracy_score(y_train, pipe.predict(X_train)))\n",
    "        test_acc.append(accuracy_score(y_test, pipe.predict(X_test)))\n",
    "\n",
    "    plt.plot(k_values, train_acc, label=f'Train p={p}')\n",
    "    plt.plot(k_values, test_acc, linestyle='--', label=f'Test p={p}')\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy/k con distancia de Minkowski (MinMaxScaler)')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta familia de curvas es coherente con KNN: en training el accuracy suele ser máximo en $k=1$ y disminuye al crecer $k$; en test aparece un pico para $k$ pequeño/medio y luego se estabiliza con pequeñas oscilaciones. Para $p=1$ y $p=2$ se obtienen valores altos y estables, mientras que $p=10$ tiende a rendir peor, sobre todo en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) ¿Cómo afecta el valor de $p$ a los resultados? ¿Qué $p$ cree que es mejor?**\n",
    "\n",
    "**Respuesta:**  \n",
    "El parámetro $p$ en la distancia de Minkowski modifica la noción de cercanía entre puntos: Intuitivamente, con $p=1$ (Manhattan) la distancia suma desvíos coordenada a coordenada y es más robusta a outliers; con $p=2$ (Euclidean) se penalizan más las discrepancias grandes pero sin quedar dominado por una única característica; con $p$ muy grande, la distancia queda básicamente determinada por la mayor diferencia individual.\n",
    "\n",
    "En este dataset, sin outliers fuertes y con varias variables informativas que contribuyen de forma moderada, $p=2$ construye vecindarios más “redondos” que aprovechan la información conjunta de los atributos, lo que explica su ligera ventaja observada (accuracy en test = 0.9708)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.Selección de atributos**\n",
    "\n",
    "**A continuación procederemos a la reducción de la dimensión de los datos.**\n",
    "\n",
    "**a) Usando el método VarianceThreshold de sklearn.feature selection para cierto umbral fijo u, elimine los atributos que no superen dicho umbral.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "u = 0.0001\n",
    "selector = VarianceThreshold(threshold=u)\n",
    "X_train_vt = selector.fit_transform(X_train)\n",
    "X_test_vt = selector.transform(X_test)\n",
    "\n",
    "print(f\"Número de características originales: {X_train.shape[1]}\")\n",
    "print(f\"Número de características seleccionadas: {X_train_vt.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota sobre el orden: VarianceThreshold debe aplicarse antes de escalar. Si escalamos primero (con StandardScaler o MinMaxScaler), alteramos la varianza y el umbral u pierde sentido. El orden correcto es: selección por varianza → escalado → KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Analice cómo afecta la selección de atributos al accuracy del modelo. Para ello, fijado un valor de $k$ para KNN, calcule accuracy en test. El conjunto de entrenamiento tendrá los atributos seleccionados para un umbral $u ∈ [0, 1]$ concreto. El resultado será una gráfica con el accuracy frente al umbral $u$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k_fixed = k_opt_dict[2]\n",
    "us = np.linspace(0, 1, 20)\n",
    "accuracies = []\n",
    "\n",
    "for u in us:\n",
    "    pipe = Pipeline([\n",
    "        ('select', VarianceThreshold(threshold=u)),  # selección SOBRE X original\n",
    "        ('scaler', MinMaxScaler()),                 # escalar SOLO las seleccionadas sin asumir normalidad\n",
    "        ('knn', KNNClassifier(k=k_fixed))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_test_pred = pipe.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "plt.plot(us, accuracies, marker='o')\n",
    "plt.xlabel(\"Umbral de varianza (u)\")\n",
    "plt.ylabel(\"Accuracy en test\")\n",
    "plt.title(f\"Impacto de VarianceThreshold en KNN (k={k_fixed}) con MinMaxScaler\")\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figura es coherente con lo esperado para VarianceThreshold. Este filtro es no supervisado: elimina atributos solo por varianza, no por relevancia. Al aumentar $u$ se quitan primero las variables de menor varianza, y la curva cambia en “escalones” cuando u supera la varianza de alguna característica. En nuestro caso, el mejor rendimiento aparece en $u≈0$ (usa todas las variables); con umbrales pequeños cae la accuracy porque se descartan algunas variables de baja varianza pero informativas; a partir de $u≈0.3$ la accuracy se estabiliza ligeramente por debajo del máximo al eliminar más variables (probablemente menos relevantes/ruidosas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) ¿Tienen sentido los casos $u=0$ y $u=1$?**\n",
    "\n",
    "**Respuesta:** Cuando $u=0$, ninguna de las columna se descarta, porque todas tienen varianza mayor a cero, lo que significa que se utilizan todas las características originales, proporcionando una referencia del rendimiento máximo del modelo. En cambio, cuando $u=1$, solo se mantienen columnas con varianza igual o mayor a 1, lo que elimina la mayoría de las características y provoca una caída notable en la exactitud del modelo, como se observa en la gráfica. \n",
    "\n",
    "Estos casos límite permiten interpretar mejor el comportamiento del modelo: el valor óptimo de $u$ estará en algún punto intermedio, donde se eliminan atributos irrelevantes pero se conservan los más importantes para mantener un buen desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Ahora seleccione los mejores atributos del conjunto de datos utilizando SelectKBest de la librería scikit-learn. Siga los siguientes pasos:**\n",
    "\n",
    "1) **Importe el método SelectKBest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Utilice una estadística univariada como f classif para la selección de atributos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **Seleccione los mejores K atributos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=10) # k es el número de atributos a seleccionar (ejemplo = 10)\n",
    "X_train_kbest = selector.fit_transform(X_train, y_train)\n",
    "X_test_kbest = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Combinando el método de selección de atributos con el clasificador KNN para un valor de $k$ fijo, determinte cuál es el mejor valor de $K$. Nótese que $k$ hace referencia al número de vecinos en KNN y $K$ es el número de atributos seleccionado.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('select', SelectKBest(score_func=f_classif)),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNNClassifier(k=5))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'select__k': list(range(1, X_train.shape[1] + 1)),\n",
    "    'knn__k': list(range(1, 31)),\n",
    "}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=inner, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores = cross_val_score(search, X_train, y_train, cv=outer, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Nested CV accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Entrena con todo el train usando los mejores hiperparámetros y evalúa en test\n",
    "search.fit(X_train, y_train)\n",
    "y_pred = search.best_estimator_.predict(X_test)\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_pred):.4f}, best params: {search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fijo = k_opt_dict[2]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('select', SelectKBest(score_func=f_classif)),  # selección ANTES de escalar\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNNClassifier(k=k_fijo))                # KNN con k fijo\n",
    "])\n",
    "\n",
    "param_grid = {'select__k': list(range(1, X_train.shape[1] + 1))}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "gridK = GridSearchCV(pipe, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "gridK.fit(X_train, y_train)\n",
    "\n",
    "best_K = gridK.best_params_['select__k']\n",
    "print(f\"Mejor K: {best_K}\")\n",
    "\n",
    "# Evaluación única en test\n",
    "y_test_pred = gridK.best_estimator_.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy en test con K={best_K} y k={k_fijo}: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K=30$ significa que SelectKBest se queda con los 30 atributos (todas las variables), es decir, \"no hubo selección\". Muchos atributos del Breast Cancer son informativos y, con KNN y el escalado dentro del Pipeline, eliminar algunos puede quitar señal útil. Además, 30 dimensiones no son altas para el tamaño del conjunto, por lo que la “maldición de la dimensionalidad” no pega fuerte aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) A continuación implemente el método de selección de atributos mRMR. Para ello, complete el archivo mRMR.py.**\n",
    "\n",
    "[Ver mRMR.py](./mRMR.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) ¿Cuál es su mejor valor de k?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mRMR import mRMR\n",
    "\n",
    "resultados = []\n",
    "max_K = 30\n",
    "mrmr_full = mRMR(n_features=max_K)\n",
    "mrmr_full.fit(X_train, y_train)\n",
    "ranking = mrmr_full.selected_idx_\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNNClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {'knn__k': list(range(1, 31))} \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for K in range(1, max_K + 1):\n",
    "    X_train_mrmr = X_train[:, ranking[:K]]\n",
    "    X_test_mrmr  = X_test[:, ranking[:K]]\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_mrmr, y_train)\n",
    "\n",
    "    resultados.append({\n",
    "        \"K_atributos\": K,\n",
    "        \"mejor_k_vecinos\": grid.best_params_['knn__k'],\n",
    "        \"accuracy_cv\": grid.best_score_,\n",
    "        \"accuracy_test\": grid.score(X_test_mrmr, y_test)\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "best_row = df_resultados.loc[df_resultados['accuracy_test'].idxmax()]\n",
    "\n",
    "mejor_k = best_row['mejor_k_vecinos']\n",
    "\n",
    "print(\"El mejor valor de k es:\", mejor_k)\n",
    "print(\"Con K =\", best_row['K_atributos'],\n",
    "      \"y accuracy_test =\", best_row['accuracy_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h) ¿Cuál es el papel de la información mutua en el método mRMR? ¿Se podría sustituir por otra métrica?**\n",
    "\n",
    "La información mutua (IM) es la métrica central del método mRMR. Se utiliza para medir:\n",
    "\n",
    "- **Relevancia:** cuánto aporta cada característica respecto a la variable objetivo, mediante la información mutua entre cada atributo y la clase.\n",
    "\n",
    "- **Redundancia:** cuánto se solapan las características entre sí, mediante la información mutua entre pares de atributos.\n",
    "\n",
    "Este enfoque permite seleccionar características que sean informativas y no repetitivas. La IM tiene la ventaja de capturar dependencias no lineales, lo que la hace más potente que métricas como la correlación.\n",
    "\n",
    "Aunque se podría sustituir por otras métricas como la correlación, el F-test o el Chi², estas alternativas no capturan relaciones complejas y no están alineadas con la formulación original de mRMR. Por tanto, sí se puede sustituir, pero no sería el método mRMR en sentido estricto.\n",
    "\n",
    "\n",
    "**i) ¿Qué método de selección de atributos, de los dos utilizados, considera que es mejor?**\n",
    "\n",
    "**mRMR** es más teórico, eficiente y explicativo. Es útil para reducir el espacio de búsqueda y evitar redundancia.\n",
    "\n",
    "**KNN** permite validar directamente qué atributos funcionan mejor con el modelo, aunque es más costoso computacionalmente.\n",
    "\n",
    "En general, mRMR es mejor como paso inicial para reducir la dimensionalidad de forma informada. Posteriormente, se puede afinar la selección usando KNN y validación cruzada.\n",
    "\n",
    "Por tanto, la combinación de ambos métodos es la más recomendable: primero mRMR para filtrar, luego KNN para validar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
