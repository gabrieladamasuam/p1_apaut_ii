{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 1: KNN y selección de atributos**\n",
    "\n",
    "**Eva Blazquez y Gabriela Damas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Implementación y uso de KNN**\n",
    "\n",
    "a) Descargue los datos del siguiente problema relacionado con el cáncer de\n",
    "mama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Preprocese el dataset siguiendo estos pasos: (1) separe los atributos de la etiquetas; (2) divida los datos en una partición con el 70 % de los puntos para training y el 30 % de los puntos para test; (3) normalice los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# (1) Separar atributos de las etiquetas\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# (2) Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# (3) Normalizar\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Si hubiera datos ausentes (missing values) y estos se completaran, ¿cómo cree que influiría el orden en el que se realizan las operaciones de normalizar y completar? ¿Qué pasaría si primero se completan los datos ausentes y luego se normaliza? ¿Y si primero se normaliza y luego se realiza la partición training-test ?\n",
    "\n",
    "**Respuesta:**  \n",
    "- Si primero completas los missing values y luego normalizas, la normalización se hace sobre datos completos, lo cual es correcto.\n",
    "- Si primero normalizas y luego completas, los valores imputados no estarán correctamente escalados respecto al resto.\n",
    "- Si primero normalizas y luego partes en train/test, puedes tener \"fugas de información\" porque la media y desviación estándar se calculan usando datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) A continuación, complete la clase KNNClassifier, cuyos atributos son el número de vecinos y una función distancia (una función cuyas entradas son dos vectores de la misma dimensión, y cuya salida es un número real positivo). Complete el constructor y los métodos fit y predict.\n",
    "\n",
    "e) Utilice la clase anterior para predecir las etiquetas de los datos de test, con un número de vecinos k, fijo pero arbitrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNNClassifier import KNNClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNNClassifier(k=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_predcustom = knn.predict(X_test_scaled)\n",
    "print(\"Accuracy en test:\", accuracy_score(y_test, y_predcustom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Responda a la siguiente pregunta: ¿Qué ocurriría si hubiera un desbalanceo de clases en el conjunto de entrenamiento? Si esto supone un problema, ¿podría proporcionar una solución?\n",
    "\n",
    "**Respuesta:** Si hay desbalanceo de clases, KNN puede estar sesgado hacia la clase mayoritaria. Una solución es ponderar el voto de los vecinos por la inversa de la distancia o usar técnicas de sobremuestreo/submuestreo, o ajustar el umbral de decisión.\n",
    "\n",
    "g) Responda a la siguiente pregunta: ¿Cuál es el coste en memoria del algoritmo KNN? ¿Se le ocurre alguna forma de reducirlo?\n",
    "\n",
    "**Respuesta:** KNN almacena todo el conjunto de entrenamiento, por lo que el coste en memoria es $O(n \\cdot d)$, siendo n el número de muestras y d el número de atributos. Para reducirlo se pueden usar prototipos (condensed KNN), clustering, o reducción de dimensionalidad.\n",
    "\n",
    "h) Utilice la función KNeighborsClassifier de la biblioteca de sklearn y, para el mismo número de vecinos k prediga las etiquetas del conjunto de test $y_{\\text{predsk}}$. Si $y_{\\text{predsk}}$ son las prediciones de su modelo, ¿cuál es el error medio entre las predicciones $y_{\\text{predsk}}$ e $y_{\\text{predcustom}}$? ¿Por qué? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "knn_sk = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_sk.fit(X_train_scaled, y_train)\n",
    "y_predsk = knn_sk.predict(X_test_scaled)\n",
    "print(\"Error medio entre predicciones:\", mean_squared_error(y_predcustom, y_predsk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Se encuentra usted a un individuo que afirma que, en vez de utilizar KNN, el prefiere usar la siguiente alternativa. Para predecir la etiqueta del punto $x$, toma los tres puntos más cercanos a $x$ en el conjunto de training. Si las distancias de estos tres puntos al punto $x$ son $d_1$, $d_2$ e $d_3$, y sus respectivas etiquetas son $y_1$, $y_2$ e $y_3$, la predicción vendrá dada por\n",
    "\n",
    "$$\n",
    "f(x) = \\operatorname{sign} \\left( \\sum_{i=1}^{3} \\frac{y_i}{d_i} \\right).\n",
    "$$\n",
    "\n",
    "¿Considera que este método es mejor que KNN con k = 3? ¿Por qué?\n",
    "\n",
    "**Respuesta 1:** El método propuesto es KNN ponderado por la inversa de la distancia. Puede ser mejor si hay vecinos cercanos de distinta clase, pero es sensible a distancias pequeñas (puede ser inestable si $d_i \\approx 0$).\n",
    "\n",
    "**Respuesta 2:** El método ponderado por la inversa de la distancia puede ser mejor si los vecinos más cercanos son más relevantes, pero es más sensible a outliers. KNN estándar da igual peso a los k vecinos. La elección depende del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Optimización de KNN**\n",
    "\n",
    "a) Encuentre, utilizando validación cruzada, el número de vecinos óptimos, $k_{\\text{opt}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor k (k_opt): 4\n",
      "Accuracy medio en CV (5-fold) para k_opt: 0.9724\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from KNNClassifier import KNNClassifier\n",
    "\n",
    "# Rango de k a evaluar (impares para evitar empates)\n",
    "k_values = list(range(1, 21))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "mean_scores = []\n",
    "for k in k_values:\n",
    "    fold_scores = []\n",
    "    for tr_idx, va_idx in cv.split(X_train_scaled, y_train):\n",
    "        X_tr, X_va = X_train_scaled[tr_idx], X_train_scaled[va_idx]\n",
    "        y_tr, y_va = y_train[tr_idx], y_train[va_idx]\n",
    "\n",
    "        knn = KNNClassifier(k=k)\n",
    "        knn.fit(X_tr, y_tr)\n",
    "        y_va_pred = knn.predict(X_va)\n",
    "        fold_scores.append(accuracy_score(y_va, y_va_pred))\n",
    "\n",
    "    mean_scores.append(np.mean(fold_scores))\n",
    "\n",
    "best_idx = int(np.argmax(mean_scores))\n",
    "k_opt = k_values[best_idx]\n",
    "best_cv_accuracy = mean_scores[best_idx]\n",
    "\n",
    "print(f\"Mejor k (k_opt): {k_opt}\")\n",
    "print(f\"Accuracy medio en CV (5-fold) para k_opt: {best_cv_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) De la métrica de accuracy sobre el conjunto de test del clasificador KNN usando el valor $k_{\\text{opt}}$ obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) ¿Cree que el valor $kopt$ encontrado es el que proporciona mejor accuracy en el conjunto de test?\n",
    "\n",
    "**Respuesta:**  \n",
    "No necesariamente. El mejor $k$ en validación cruzada sobre train puede no ser el mejor en test, pero suele generalizar bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Muestre en una gráfica el accuracy frente al número de vecinos, tanto para el conjunto de training como para el de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Repita los experimentos anteriores utilizando la distancia de Minkowski para $p ∈ {1, 2, 10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) ¿Cómo afecta el valor de $p$ a los resultados? ¿Qué $p$ cree que es mejor?\n",
    "\n",
    "**Respuesta:**  \n",
    "Valores bajos de $p$ (como 1) dan más peso a diferencias individuales, valores altos (como 10) hacen que la distancia esté dominada por la mayor diferencia. Suele funcionar mejor $p=2$ (euclídea) o $p=1$ (Manhattan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.Selección de atributos**\n",
    "\n",
    "A continuación procederemos a la reducción de la dimensión de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Usando el método VarianceThreshold de sklearn.feature selection para cierto umbral fijo u, elimine los atributos que no superen dicho umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Analice cómo afecta la selección de atributos al accuracy del modelo. Para ello, fijado un valor de k para KNN, calcule accuracy en test. El conjunto de entrenamiento tendr ́a los atributos seleccionados para un umbral $u ∈ [0, 1]$ concreto. El resultado ser ́a una gr ́afica con el accuracy frente al umbral $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) ¿Tienen sentido los casos $u=0$ y $u=1$?\n",
    "\n",
    "**Respuesta:**  \n",
    "$u=0$: no se elimina ningún atributo (salvo los constantes).  \n",
    "$u=1$: probablemente elimina todos los atributos (varianzas suelen ser <1 tras normalizar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Ahora seleccione los mejores atributos del conjunto de datos utilizando SelectKBest de la librería scikit-learn. Siga los siguientes pasos:\n",
    "\n",
    "1) Importe el método SelectKBest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Utilice una estadística univariada como f classif para la selección de atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Seleccione los mejores K atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=K)\n",
    "selector.fit(X, y)\n",
    "X_selected = selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recuerda:**  \n",
    "Debes completar también la clase `mRMR.py` para la selección de atributos basada en relevancia y redundancia, y documentar todo en tu notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Combinando el método de selección de atributos con el clasificador KNN para un valor de k fijo, determinte cuál es el mejor valor de K. Nótese que k hace referencia al número de vecinos en KNN y K es el número de atributos seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) A continuación implemente el método de selección de atributos mRMR. Para ello, complete el archivo mRMR.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) ¿Cuál es su mejor valor de k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) ¿Cuál es el papel de la información mutua en el método mRMR? ¿Se podría sustituir por otra métrica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) ¿Qué método de selección de atributos, de los dos utilizados, considera que es mejor?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
